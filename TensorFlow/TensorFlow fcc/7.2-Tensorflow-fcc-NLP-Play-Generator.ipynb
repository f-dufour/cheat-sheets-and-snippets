{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7.2-Tensorflow-fcc-NLP-Play-Generator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNsxIMQ6MYOrvBlhnRgIGP+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["- NLP w/ RNN: Generate play\n","- Florent Dufour\n","- 2016 - 2022"],"metadata":{"id":"zT9KTV5POJM2"}},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","from keras.preprocessing import sequence\n","import numpy as np\n","import os"],"metadata":{"id":"iKnh4bYS5vyT","executionInfo":{"status":"ok","timestamp":1645463253766,"user_tz":-60,"elapsed":4607,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Dataset: R&J - Shakespeare\n","path_to_file = tf.keras.utils.get_file(\"Shakespeare.txt\", 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAt6ta7456az","executionInfo":{"status":"ok","timestamp":1645463253767,"user_tz":-60,"elapsed":13,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"dae5fcbc-e341-401c-c270-527372d4a3ba"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n","1130496/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["text = open(path_to_file, 'rb').read().decode(encoding=\"utf-8\")\n","print(len(text)) # 1115394 characters\n","print(text[:500])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CVI84vw6Kyx","executionInfo":{"status":"ok","timestamp":1645463253767,"user_tz":-60,"elapsed":9,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"84bc9772-bcbe-4bb2-8346-e056ed8a287c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1115394\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor\n"]}]},{"cell_type":"code","source":["# Pre-processing: Encode as integers\n","\n","vocab = sorted(set(text))\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","def text_to_int(text):\n","  return np.array([char2idx[c] for c in text])\n","\n","text_as_int = text_to_int(text)\n","\n","print(\"Text:\", text[:13])\n","print(\"Encoded:\", text_to_int(text[:13]))\n","\n","def int_to_text(ints):\n","  try:\n","    ints = ints.numpy()\n","  except:\n","    pass\n","  return ''.join(idx2char[ints])\n","\n","print(int_to_text(text_as_int[:13]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYEY9x3G6o2b","executionInfo":{"status":"ok","timestamp":1645463254424,"user_tz":-60,"elapsed":661,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"9b7cc303-6222-42d0-c58f-68e04b843d4b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Text: First Citizen\n","Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n","First Citizen\n"]}]},{"cell_type":"code","source":["seq_length = 100  # length of sequence for a training example\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","# Create training examples / targets\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","\n","sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","def split_input_target(chunk):  # for the example: hello\n","    input_text = chunk[:-1]  # hell\n","    target_text = chunk[1:]  # ello\n","    return input_text, target_text  # hell, ello\n","\n","dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry\n","\n","for x, y in dataset.take(2):\n","  print(\"\\n\\nEXAMPLE\\n\")\n","  print(\"INPUT\")\n","  print(int_to_text(x))\n","  print(\"\\nOUTPUT\")\n","  print(int_to_text(y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aR6Tt2R9_4u","executionInfo":{"status":"ok","timestamp":1645463258605,"user_tz":-60,"elapsed":4184,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"1eae12bb-ff01-4ec9-b577-33a50cc8a5dc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","EXAMPLE\n","\n","INPUT\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n","\n","OUTPUT\n","irst Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You \n","\n","\n","EXAMPLE\n","\n","INPUT\n","are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you \n","\n","OUTPUT\n","re all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you k\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n","EMBEDDING_DIM = 256\n","RNN_UNITS = 1024\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"alDUrNXE-M1u","executionInfo":{"status":"ok","timestamp":1645463258605,"user_tz":-60,"elapsed":7,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Building the model\n","\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n","model.summary()"],"metadata":{"id":"eHnIuQ1R_lVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645463259741,"user_tz":-60,"elapsed":1141,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"1a1e9f2d-006c-44b1-d39d-167ff56b56d0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (64, None, 256)           16640     \n","                                                                 \n"," lstm (LSTM)                 (64, None, 1024)          5246976   \n","                                                                 \n"," dense (Dense)               (64, None, 65)            66625     \n","                                                                 \n","=================================================================\n","Total params: 5,330,241\n","Trainable params: 5,330,241\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Loss function\n","\n","for input_example_batch, target_example_batch in data.take(1):\n","  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n","  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape\n","\n","# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n","print(len(example_batch_predictions))\n","print(example_batch_predictions)\n","\n","# lets examine one prediction\n","pred = example_batch_predictions[0]\n","print(len(pred))\n","print(pred)\n","# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step\n","\n","# and finally well look at a prediction at the first timestep\n","time_pred = pred[0]\n","print(len(time_pred))\n","print(time_pred)\n","# and of course its 65 values representing the probabillity of each character occuring next\n","\n","# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n","sampled_indices = tf.random.categorical(pred, num_samples=1)\n","\n","# now we can reshape that array and convert all the integers to numbers to see the actual characters\n","sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n","predicted_chars = int_to_text(sampled_indices)\n","\n","predicted_chars  # and this is what the model predicted for training sequence 1\n","\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dibDpYD0OQ3Q","executionInfo":{"status":"ok","timestamp":1645463266128,"user_tz":-60,"elapsed":6391,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"f9c5c8fb-43a9-4233-a77d-0fb10fd25b77"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n","64\n","tf.Tensor(\n","[[[-2.80629168e-03 -8.31973739e-06 -1.36144727e-03 ... -8.85163317e-04\n","   -2.20908760e-03 -3.48567846e-03]\n","  [ 5.64133609e-03  1.81904261e-03 -4.98019042e-04 ... -4.41337004e-04\n","   -3.07981251e-03 -1.13467372e-03]\n","  [ 2.60318490e-03  7.64396507e-03  1.73502672e-03 ...  2.05316721e-03\n","    1.03418413e-03 -7.25862291e-03]\n","  ...\n","  [-1.09323002e-02 -2.83308653e-03 -3.98997799e-04 ...  2.21677800e-03\n","    1.38025684e-02 -3.89999268e-03]\n","  [-1.17545109e-02 -4.93227551e-03 -1.40566402e-03 ... -3.60211590e-04\n","    1.20199565e-02 -4.21045348e-03]\n","  [-2.27116933e-03 -2.70372862e-03 -6.52246526e-04 ... -1.23163802e-04\n","    8.45741853e-03 -6.70667039e-04]]\n","\n"," [[-1.36682508e-03  9.64666484e-04 -3.46181914e-03 ... -2.97155185e-03\n","    4.88506351e-03 -6.50231552e-04]\n","  [ 1.95196015e-03 -3.64710065e-03  2.29514018e-03 ... -4.35468461e-03\n","    8.56598374e-03 -2.60676187e-03]\n","  [ 2.54668994e-04  2.51209969e-03  4.08339594e-03 ... -1.14090485e-03\n","    1.06224203e-02 -8.52215011e-03]\n","  ...\n","  [-1.03088813e-02 -6.70723524e-03  1.31905684e-03 ...  1.98226864e-03\n","    1.93996960e-03 -5.46677690e-03]\n","  [-9.66859702e-03  1.93293137e-03  5.22557646e-03 ...  3.56583740e-03\n","    5.02495933e-03 -1.19610522e-02]\n","  [-1.28078368e-02 -7.49556464e-04  1.96657353e-03 ...  1.74395042e-03\n","    1.71473692e-03 -1.03351343e-02]]\n","\n"," [[-1.38852256e-03 -2.07216712e-04 -2.53898767e-03 ...  2.68648285e-03\n","    1.89327262e-03 -1.17255072e-03]\n","  [ 5.51351067e-03  2.19348725e-03 -5.76713355e-04 ...  1.70833815e-03\n","   -2.88300216e-05 -1.27766817e-03]\n","  [-8.42265901e-04  6.32998708e-05 -1.53780147e-03 ... -1.38022029e-03\n","    3.86293977e-05 -3.82787292e-03]\n","  ...\n","  [ 4.43091616e-03 -7.58186914e-04  1.05454493e-03 ... -7.30007468e-03\n","   -5.65198576e-03  9.29564703e-03]\n","  [ 3.84006067e-03  3.06737493e-03 -6.78473152e-05 ... -8.26739334e-03\n","   -4.08228999e-03  9.01915599e-03]\n","  [ 9.26845241e-03 -1.28858932e-03  6.33585267e-04 ... -9.70803946e-03\n","   -3.30494344e-03  8.47130828e-03]]\n","\n"," ...\n","\n"," [[-3.50200827e-03  7.43234344e-03  3.67346685e-03 ... -5.11332881e-03\n","   -2.90567614e-03  1.67247257e-03]\n","  [-7.19747134e-03  8.43556039e-03  4.04769089e-05 ... -7.61184655e-03\n","    8.57319974e-04  1.42689329e-04]\n","  [-1.16083827e-02  1.06847612e-04 -4.66325693e-03 ... -5.98815409e-03\n","    1.15131121e-03 -4.87298798e-03]\n","  ...\n","  [-3.54327098e-03 -3.46480520e-03  1.05695035e-02 ...  4.69223189e-04\n","   -3.65767488e-03 -2.85744201e-03]\n","  [-2.79982993e-03  3.74461338e-03  1.02265812e-02 ...  1.44977123e-03\n","   -5.81693556e-03 -1.40615518e-03]\n","  [-3.70800262e-03  3.75035219e-03  4.66952659e-03 ... -1.85166101e-03\n","   -9.13325930e-05 -1.69446319e-03]]\n","\n"," [[-1.33724138e-03  6.27110340e-03  2.66042794e-03 ...  2.47064955e-03\n","    3.49804899e-03 -7.08663650e-03]\n","  [-8.20825808e-03 -1.84991630e-04 -2.52874522e-03 ...  9.67615633e-04\n","    3.56370537e-03 -9.09624249e-03]\n","  [-7.15820026e-03 -5.79982530e-03  6.64058840e-04 ...  1.12071517e-03\n","    5.14452462e-04 -8.87310132e-03]\n","  ...\n","  [-1.08557260e-02  4.21323115e-03  8.89639743e-03 ...  3.57400603e-03\n","    4.51647211e-03 -4.95724473e-03]\n","  [-8.66375864e-03  1.47422496e-03  8.21308978e-03 ...  3.45519581e-03\n","    9.47812339e-04 -2.32881890e-03]\n","  [-1.25557166e-02 -2.08190712e-03  4.70998697e-03 ...  8.91616335e-04\n","    9.73447633e-04 -2.63405708e-03]]\n","\n"," [[-4.74236766e-03  4.38662991e-03  3.45916580e-03 ...  2.04302953e-03\n","    5.19114360e-03  8.00655689e-05]\n","  [-5.34655526e-03  4.88452101e-03  9.24459891e-04 ... -1.38656236e-03\n","    8.68881494e-03 -6.81738427e-04]\n","  [-1.16895726e-02 -4.37883893e-04 -3.65562737e-03 ... -1.93092762e-03\n","    6.19671587e-03  1.37740071e-03]\n","  ...\n","  [-1.23444488e-02  4.35647368e-03  3.42043070e-03 ...  1.74168113e-03\n","    7.03587849e-03 -1.01130838e-02]\n","  [-1.52779743e-02  1.02498522e-02  6.82800822e-03 ... -3.91170057e-03\n","    2.64110835e-03 -4.57357941e-03]\n","  [-1.70386601e-02  4.53291414e-03  3.75251565e-03 ... -4.10474185e-03\n","    2.35703308e-03 -5.48369531e-03]]], shape=(64, 100, 65), dtype=float32)\n","100\n","tf.Tensor(\n","[[-2.80629168e-03 -8.31973739e-06 -1.36144727e-03 ... -8.85163317e-04\n","  -2.20908760e-03 -3.48567846e-03]\n"," [ 5.64133609e-03  1.81904261e-03 -4.98019042e-04 ... -4.41337004e-04\n","  -3.07981251e-03 -1.13467372e-03]\n"," [ 2.60318490e-03  7.64396507e-03  1.73502672e-03 ...  2.05316721e-03\n","   1.03418413e-03 -7.25862291e-03]\n"," ...\n"," [-1.09323002e-02 -2.83308653e-03 -3.98997799e-04 ...  2.21677800e-03\n","   1.38025684e-02 -3.89999268e-03]\n"," [-1.17545109e-02 -4.93227551e-03 -1.40566402e-03 ... -3.60211590e-04\n","   1.20199565e-02 -4.21045348e-03]\n"," [-2.27116933e-03 -2.70372862e-03 -6.52246526e-04 ... -1.23163802e-04\n","   8.45741853e-03 -6.70667039e-04]], shape=(100, 65), dtype=float32)\n","65\n","tf.Tensor(\n","[-2.8062917e-03 -8.3197374e-06 -1.3614473e-03  1.9985507e-04\n","  1.0593508e-03  4.6417140e-04  2.5814418e-03  3.0006568e-03\n","  2.8452239e-04  6.1056763e-03  3.7354275e-03 -1.8873158e-03\n","  4.8554572e-04  6.2970852e-04 -2.5584994e-04  4.2305901e-03\n","  1.3481418e-04 -4.5190793e-03 -5.1107425e-03 -3.9259158e-03\n","  6.3226064e-04 -2.0895237e-03  7.8374380e-04  4.5785774e-03\n","  3.4836479e-03 -3.0520321e-03 -1.3202869e-03  1.1099051e-03\n","  2.7280601e-03  4.3366021e-03  2.6598959e-03 -2.0011412e-03\n","  5.6278720e-03  5.0297743e-03 -5.0246902e-03 -4.4525829e-03\n"," -8.0378074e-03  3.9196564e-03 -7.4652657e-03 -2.7938341e-03\n","  5.9145526e-03  2.5738007e-03 -2.5627729e-03 -1.2549361e-03\n"," -5.5580591e-03  2.0976719e-03 -1.2314247e-03  5.8875373e-04\n","  1.7260975e-03  1.8470939e-03  3.9409976e-03  1.6691636e-03\n"," -3.1325673e-03 -2.5671034e-03  2.7343826e-03 -3.7134415e-03\n","  9.9609140e-05  3.0117251e-03 -2.7499888e-03 -5.1239459e-03\n"," -1.7805770e-04 -2.5482345e-03 -8.8516332e-04 -2.2090876e-03\n"," -3.4856785e-03], shape=(65,), dtype=float32)\n"]}]},{"cell_type":"code","source":["# Compiling the model\n","\n","model.compile(optimizer='adam', loss=loss)\n","\n","# Checkpoints\n","\n","# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"metadata":{"id":"efC-8LCbOail","executionInfo":{"status":"ok","timestamp":1645463266129,"user_tz":-60,"elapsed":8,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Training\n","\n","history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])\n","model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1, None]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAQwTQYxOhzB","executionInfo":{"status":"ok","timestamp":1645464094098,"user_tz":-60,"elapsed":827975,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"3259a5a9-00f6-4913-a373-2ef14b91e6b1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","172/172 [==============================] - 15s 63ms/step - loss: 2.6806\n","Epoch 2/50\n","172/172 [==============================] - 12s 64ms/step - loss: 1.9799\n","Epoch 3/50\n","172/172 [==============================] - 13s 65ms/step - loss: 1.7143\n","Epoch 4/50\n","172/172 [==============================] - 13s 66ms/step - loss: 1.5678\n","Epoch 5/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.4784\n","Epoch 6/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.4183\n","Epoch 7/50\n","172/172 [==============================] - 14s 68ms/step - loss: 1.3746\n","Epoch 8/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.3383\n","Epoch 9/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.3062\n","Epoch 10/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.2781\n","Epoch 11/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.2502\n","Epoch 12/50\n","172/172 [==============================] - 13s 69ms/step - loss: 1.2225\n","Epoch 13/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.1966\n","Epoch 14/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.1686\n","Epoch 15/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.1388\n","Epoch 16/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.1090\n","Epoch 17/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.0766\n","Epoch 18/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.0446\n","Epoch 19/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.0098\n","Epoch 20/50\n","172/172 [==============================] - 13s 69ms/step - loss: 0.9753\n","Epoch 21/50\n","172/172 [==============================] - 13s 69ms/step - loss: 0.9403\n","Epoch 22/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.9051\n","Epoch 23/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.8717\n","Epoch 24/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.8376\n","Epoch 25/50\n","172/172 [==============================] - 14s 69ms/step - loss: 0.8037\n","Epoch 26/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7739\n","Epoch 27/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7447\n","Epoch 28/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7160\n","Epoch 29/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6898\n","Epoch 30/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6665\n","Epoch 31/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6447\n","Epoch 32/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6236\n","Epoch 33/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6054\n","Epoch 34/50\n","172/172 [==============================] - 13s 69ms/step - loss: 0.5883\n","Epoch 35/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5714\n","Epoch 36/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5560\n","Epoch 37/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5435\n","Epoch 38/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5310\n","Epoch 39/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5200\n","Epoch 40/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5097\n","Epoch 41/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5004\n","Epoch 42/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4900\n","Epoch 43/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4822\n","Epoch 44/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4750\n","Epoch 45/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4688\n","Epoch 46/50\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4637\n","Epoch 47/50\n","172/172 [==============================] - 14s 73ms/step - loss: 0.4558\n","Epoch 48/50\n","172/172 [==============================] - 14s 75ms/step - loss: 0.4516\n","Epoch 49/50\n","172/172 [==============================] - 14s 74ms/step - loss: 0.4457\n","Epoch 50/50\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4418\n"]}]},{"cell_type":"code","source":["# Load checkpoints\n","\n","# checkpoint_num = 10\n","# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n","# model.build(tf.TensorShape([1, None]))"],"metadata":{"id":"PNSxRb18PcQc","executionInfo":{"status":"ok","timestamp":1645464094100,"user_tz":-60,"elapsed":13,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Generating text\n","\n","def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 800\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 1.0\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","    \n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the character returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted character as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"metadata":{"id":"Oi1EJE0sPhaX","executionInfo":{"status":"ok","timestamp":1645464094101,"user_tz":-60,"elapsed":10,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["inp = input(\"Type a starting string: \")\n","print(generate_text(model, inp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwPLh2XZQ7eu","executionInfo":{"status":"ok","timestamp":1645464121764,"user_tz":-60,"elapsed":9803,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}},"outputId":"ef2f470b-cc1e-499b-b925-94b6fd8893b8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Type a starting string: Romeo then said\n","Romeo then said 'That meet,\n","How effection now, nor want of death?\n","O same advice four.\n","\n","LARTIUS:\n","O, that's the case is most out of hope, I say.\n","\n","HASTINGS:\n","My Lord of Buckingham, now putting over mine eyes,\n","Men are be no better endured both your hands;\n","Gives steal thoughts of carries none but toil; how it is your name? I humy welcome;\n","And, by the airy word! Believe me, love!\n","\n","VOLUMNIA:\n","If I do bring thee hence to Friar Lodowick to his captain Christ,\n","Under whose colours yet I oft it not:\n","He hath the demedness home again with the entraits of your dear.\n","\n","Lord:\n","Those cordial, Duft that, thy taughters, who loss of her,\n","Upon my cousin; let my brother die,\n","I fearn us not.\n","\n","MENENIUS:\n","O' the treacherous vengeance on offenders' fest\n","Unto the brother and the canopy for\n","Your brother's life? or sign from see, since th\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"c0UHdaKsTcjo","executionInfo":{"status":"ok","timestamp":1645464121765,"user_tz":-60,"elapsed":6,"user":{"displayName":"Florent Dufour","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb1xkeK5CuuX0arwIASP1IAgMUBXBBzCaDLSJYQw=s64","userId":"06001106705548366077"}}},"execution_count":13,"outputs":[]}]}